{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Performance wasn't very good. Predict week by week and calc moving average for next week!\n",
    "Steps: \n",
    "- a) Split up test set by week\n",
    "- b) Give week 1 the same EWMA as the last week in the training set.\n",
    "- c) Predict week 1\n",
    "- d) Calc EWMA for following week\n",
    "- e) Predict following week\n",
    "- f) Repeat d & e until all predictions are made."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "mingw_path = 'C:\\\\Program Files\\\\mingw-w64\\\\x86_64-7.2.0-posix-seh-rt_v5-rev1\\\\mingw64\\\\bin'\n",
    "os.environ['PATH'] = mingw_path + ';' + os.environ['PATH']\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import gc # Note: this is a garbage collector\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bring in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = r\"..\\Raw_Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'airRes':    pd.read_csv(PATH + r\"\\air_reserve.csv\"),\n",
    "    'airStore':  pd.read_csv(PATH + r\"\\air_store_info.csv\"),\n",
    "    'airVisit':  pd.read_csv(PATH + r\"\\air_visit_data.csv\"),\n",
    "    'date':      pd.read_csv(PATH + r\"\\date_info.csv\"),\n",
    "    'hpgRes':    pd.read_csv(PATH + r\"\\hpg_reserve.csv\"),\n",
    "    'hpgStore':  pd.read_csv(PATH + r\"\\hpg_store_info.csv\"),\n",
    "    'sampleSub': pd.read_csv(PATH + r\"\\sample_submission.csv\"),\n",
    "    'storeIDs':  pd.read_csv(PATH + r\"\\store_id_relation.csv\")    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['airStore'].tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['airVisit'].head(15)\n",
    "#data['airRes'].reserve_datetime.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['date']['visit_date'] = pd.to_datetime(data['date']['calendar_date'])\n",
    "data['date'].drop('calendar_date', axis = 1 , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['airVisit']['visit_date'] = pd.to_datetime(data['airVisit']['visit_date'])\n",
    "data['airVisit']['dow'] = data['airVisit']['visit_date'].dt.dayofweek\n",
    "data['airVisit']['year'] = data['airVisit']['visit_date'].dt.year\n",
    "data['airVisit']['month'] = data['airVisit']['visit_date'].dt.month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add EWMA of visits as feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate ewm (note, found this on the discussion forum):\n",
    "def calc_shifted_ewm(series, alpha, adjust = True):\n",
    "    return series.shift().ewm(alpha = alpha, adjust = adjust).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step below adds the ewm by day of week. Right now I'm returning a separate series so I can look at what each step does if I want to\n",
    "tmp = data['airVisit'].groupby(['air_store_id','dow']).apply(lambda x: calc_shifted_ewm(x['visitors'], 0.1)) \n",
    "# This step backfills the 1st week's dow for each restaurant, otherwise it would be NaN since it's a 1-period ewma\n",
    "tmp = tmp.fillna(method='bfill')\n",
    "# The groupby function returns a multiIndex Series. I only need the 3rd level (original df index) to add column to original df\n",
    "tmp.index = tmp.index.get_level_values(2)\n",
    "# Sort index before adding back to original df\n",
    "tmp = tmp.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['airVisit']['ewma'] = tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add 'days since last' and 'days until next' holiday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 'days since holiday' feature\n",
    "daysSinceList = []\n",
    "daysSinceHol = 0 # initialize daysSince counter\n",
    "for row in data['date']['holiday_flg']:\n",
    "    if row == 1:\n",
    "        daysSinceHol = 0\n",
    "        daysSinceList.append(daysSinceHol)\n",
    "    else:\n",
    "        daysSinceHol += 1\n",
    "        daysSinceList.append(daysSinceHol)\n",
    "data['date']['days_since_holiday'] = daysSinceList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 'days UNTIL next holiday' feature\n",
    "holidayList = list(data['date']['holiday_flg'])\n",
    "daysUntilHolList = np.zeros(len(holidayList),dtype=np.int)\n",
    "daysUntilHol = 0 # initialize daysUntilHol counter\n",
    "for i in range(len(holidayList)-1,0,-1):\n",
    "    if holidayList[i] == 1:\n",
    "        daysUntilHol = 0\n",
    "        daysUntilHolList[i] = daysUntilHol\n",
    "    else:\n",
    "        daysUntilHol += 1\n",
    "        daysUntilHolList[i] = daysUntilHol        \n",
    "data['date']['days_until_holiday'] = daysUntilHolList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge air_visits with date dframe to get holiday info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "colsToMerge = ['holiday_flg','visit_date','days_until_holiday','days_since_holiday']\n",
    "df_train = pd.merge(data['airVisit'], data['date'][colsToMerge], how = 'left', on = 'visit_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter only the stores that must be predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = data['sampleSub']\n",
    "\n",
    "df_test['visit_date'] = df_test['id'].map(lambda x: str(x).split('_')[2])\n",
    "df_test['air_store_id'] = df_test['id'].map(lambda x: '_'.join(str(x).split('_')[:2]))\n",
    "df_test['visit_date'] = pd.to_datetime(df_test['visit_date'])\n",
    "df_test['dow'] = df_test['visit_date'].dt.dayofweek\n",
    "df_test['year'] = df_test['visit_date'].dt.year\n",
    "df_test['month'] = df_test['visit_date'].dt.month\n",
    "\n",
    "unique_stores = df_test['air_store_id'].unique()\n",
    "stores = pd.concat([pd.DataFrame({'air_store_id': unique_stores, 'dow': [i]*len(unique_stores)}) for i in range(7)], axis=0, ignore_index=True).reset_index(drop=True)\n",
    "#stores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge df_test with date dframe to get holiday info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.merge(df_test, data['date'][colsToMerge], how = 'left', on = 'visit_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores = pd.merge(stores, data['airStore'], how='left', on=['air_store_id'])\n",
    "#stores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical string variables \n",
    "lbl = LabelEncoder()\n",
    "stores['air_genre_name'] = lbl.fit_transform(stores['air_genre_name'])\n",
    "stores['air_area_name'] = lbl.fit_transform(stores['air_area_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>dow</th>\n",
       "      <th>air_genre_name</th>\n",
       "      <th>air_area_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>44</td>\n",
       "      <td>35.694003</td>\n",
       "      <td>139.753595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_0164b9927d20bcc3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>62</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_0241aa3964b7f861</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>82</td>\n",
       "      <td>35.712607</td>\n",
       "      <td>139.779996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_0328696196e46f18</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>98</td>\n",
       "      <td>34.701279</td>\n",
       "      <td>135.528090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_034a3d5b40d5b1b1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>102</td>\n",
       "      <td>34.692337</td>\n",
       "      <td>135.472229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id  dow  air_genre_name  air_area_name   latitude  \\\n",
       "0  air_00a91d42b08b08d9    0               6             44  35.694003   \n",
       "1  air_0164b9927d20bcc3    0               6             62  35.658068   \n",
       "2  air_0241aa3964b7f861    0               7             82  35.712607   \n",
       "3  air_0328696196e46f18    0               4             98  34.701279   \n",
       "4  air_034a3d5b40d5b1b1    0               2            102  34.692337   \n",
       "\n",
       "    longitude  \n",
       "0  139.753595  \n",
       "1  139.751599  \n",
       "2  139.779996  \n",
       "3  135.528090  \n",
       "4  135.472229  "
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add genre and area to train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.merge(df_train, stores, how = 'left', on = ['air_store_id','dow'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add visitor statistics as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "air_store_id          False\n",
       "visit_date            False\n",
       "visitors              False\n",
       "dow                   False\n",
       "year                  False\n",
       "month                 False\n",
       "ewma                  False\n",
       "holiday_flg           False\n",
       "days_until_holiday    False\n",
       "days_since_holiday    False\n",
       "air_genre_name         True\n",
       "air_area_name          True\n",
       "latitude               True\n",
       "longitude              True\n",
       "min_visitors          False\n",
       "mean_visitors         False\n",
       "median_visitors       False\n",
       "max_visitors          False\n",
       "count_observations    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = df_train.groupby(['air_store_id','dow']).agg({'visitors' : [np.min,np.mean,np.median,np.max,np.size]}).reset_index()\n",
    "tmp.columns = ['air_store_id', 'dow', 'min_visitors', 'mean_visitors', 'median_visitors','max_visitors','count_observations']\n",
    "#stores = pd.merge(df_train, tmp, how='left', on=['air_store_id','dow'])\n",
    "df_train = pd.merge(df_train, tmp, how='left', on=['air_store_id','dow'])\n",
    "#print(df_train.columns)\n",
    "#print(df_train.head())\n",
    "df_train.isnull().any()\n",
    "#print(stores.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONTINUE HERE: Add statistics to test set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                    False\n",
       "visitors              False\n",
       "visit_date            False\n",
       "air_store_id          False\n",
       "dow                   False\n",
       "year                  False\n",
       "month                 False\n",
       "holiday_flg           False\n",
       "days_until_holiday    False\n",
       "days_since_holiday    False\n",
       "air_genre_name        False\n",
       "air_area_name         False\n",
       "latitude              False\n",
       "longitude             False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.merge(df_test, stores, how = 'left', on = ['air_store_id','dow'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>visitors</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>dow</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>holiday_flg</th>\n",
       "      <th>days_until_holiday</th>\n",
       "      <th>days_since_holiday</th>\n",
       "      <th>air_genre_name</th>\n",
       "      <th>air_area_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>min_visitors</th>\n",
       "      <th>mean_visitors</th>\n",
       "      <th>median_visitors</th>\n",
       "      <th>max_visitors</th>\n",
       "      <th>count_observations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-23</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>6</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>34</td>\n",
       "      <td>6</td>\n",
       "      <td>44</td>\n",
       "      <td>35.694003</td>\n",
       "      <td>139.753595</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-24</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-04-24</td>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>6</td>\n",
       "      <td>44</td>\n",
       "      <td>35.694003</td>\n",
       "      <td>139.753595</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.457143</td>\n",
       "      <td>19.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-25</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-04-25</td>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "      <td>6</td>\n",
       "      <td>44</td>\n",
       "      <td>35.694003</td>\n",
       "      <td>139.753595</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.350000</td>\n",
       "      <td>24.5</td>\n",
       "      <td>43.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-26</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-04-26</td>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>37</td>\n",
       "      <td>6</td>\n",
       "      <td>44</td>\n",
       "      <td>35.694003</td>\n",
       "      <td>139.753595</td>\n",
       "      <td>15.0</td>\n",
       "      <td>28.125000</td>\n",
       "      <td>28.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-27</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-04-27</td>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>6</td>\n",
       "      <td>44</td>\n",
       "      <td>35.694003</td>\n",
       "      <td>139.753595</td>\n",
       "      <td>15.0</td>\n",
       "      <td>29.868421</td>\n",
       "      <td>30.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id  visitors visit_date          air_store_id  \\\n",
       "0  air_00a91d42b08b08d9_2017-04-23         0 2017-04-23  air_00a91d42b08b08d9   \n",
       "1  air_00a91d42b08b08d9_2017-04-24         0 2017-04-24  air_00a91d42b08b08d9   \n",
       "2  air_00a91d42b08b08d9_2017-04-25         0 2017-04-25  air_00a91d42b08b08d9   \n",
       "3  air_00a91d42b08b08d9_2017-04-26         0 2017-04-26  air_00a91d42b08b08d9   \n",
       "4  air_00a91d42b08b08d9_2017-04-27         0 2017-04-27  air_00a91d42b08b08d9   \n",
       "\n",
       "   dow  year  month  holiday_flg  days_until_holiday  days_since_holiday  \\\n",
       "0    6  2017      4            0                   6                  34   \n",
       "1    0  2017      4            0                   5                  35   \n",
       "2    1  2017      4            0                   4                  36   \n",
       "3    2  2017      4            0                   3                  37   \n",
       "4    3  2017      4            0                   2                  38   \n",
       "\n",
       "   air_genre_name  air_area_name   latitude   longitude  min_visitors  \\\n",
       "0               6             44  35.694003  139.753595           2.0   \n",
       "1               6             44  35.694003  139.753595           1.0   \n",
       "2               6             44  35.694003  139.753595           1.0   \n",
       "3               6             44  35.694003  139.753595          15.0   \n",
       "4               6             44  35.694003  139.753595          15.0   \n",
       "\n",
       "   mean_visitors  median_visitors  max_visitors  count_observations  \n",
       "0       2.000000              2.0           2.0                 1.0  \n",
       "1      22.457143             19.0          47.0                35.0  \n",
       "2      24.350000             24.5          43.0                40.0  \n",
       "3      28.125000             28.0          52.0                40.0  \n",
       "4      29.868421             30.0          47.0                38.0  "
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.merge(df_test, tmp, how='left', on=['air_store_id','dow'])\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, I'm just using fillna on the train set. TODO: investigate why there are NaN on train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.fillna(-1)\n",
    "df_test = df_test.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_train\n",
    "test = df_test\n",
    "col = [c for c in train if c not in ['id', 'air_store_id','visit_date','visitors']]\n",
    "#test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize XGBoost\n",
    "Note - code based on:\n",
    "https://www.kaggle.com/jmbull/no-xgb-starter-here-s-one-lb-507"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binding to float32\n"
     ]
    }
   ],
   "source": [
    "# XGB starter template borrowed from @anokas\n",
    "# https://www.kaggle.com/anokas/simple-xgboost-starter-0-0655\n",
    "\n",
    "print('Binding to float32')\n",
    "\n",
    "for c, dtype in zip(df_train.columns, train.dtypes):\n",
    "    if dtype == np.float64:\n",
    "        train[c] = train[c].astype(np.float32)\n",
    "        \n",
    "for c, dtype in zip(df_test.columns, test.dtypes):\n",
    "    if dtype == np.float64:\n",
    "        test[c] = test[c].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train.drop(['air_store_id','visit_date','visitors'], axis=1)\n",
    "y_train = np.log1p(train['visitors'].values)\n",
    "\n",
    "# Get Column order for x_test df\n",
    "colOrder = x_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(252108, 16) (252108,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape)\n",
    "#print(colOrder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building DMatrix...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "231"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create training / validation split\n",
    "split = 200000\n",
    "x_train, y_train, x_valid, y_valid = x_train[:split], y_train[:split], x_train[split:], y_train[split:]\n",
    "\n",
    "print('Building DMatrix...')\n",
    "\n",
    "d_train = xgb.DMatrix(x_train, label=y_train)\n",
    "d_valid = xgb.DMatrix(x_valid, label=y_valid)\n",
    "\n",
    "del x_train, x_valid; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ...\n",
      "[0]\ttrain-rmse:2.35531\tvalid-rmse:2.31585\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 100 rounds.\n",
      "[10]\ttrain-rmse:1.61232\tvalid-rmse:1.58725\n",
      "[20]\ttrain-rmse:1.13761\tvalid-rmse:1.12118\n",
      "[30]\ttrain-rmse:0.84573\tvalid-rmse:0.834624\n",
      "[40]\ttrain-rmse:0.676642\tvalid-rmse:0.668327\n",
      "[50]\ttrain-rmse:0.585418\tvalid-rmse:0.578816\n",
      "[60]\ttrain-rmse:0.539181\tvalid-rmse:0.533684\n",
      "[70]\ttrain-rmse:0.516395\tvalid-rmse:0.511711\n",
      "[80]\ttrain-rmse:0.505054\tvalid-rmse:0.501227\n",
      "[90]\ttrain-rmse:0.499031\tvalid-rmse:0.496156\n",
      "[100]\ttrain-rmse:0.49554\tvalid-rmse:0.493567\n",
      "[110]\ttrain-rmse:0.493237\tvalid-rmse:0.492162\n",
      "[120]\ttrain-rmse:0.491513\tvalid-rmse:0.49128\n",
      "[130]\ttrain-rmse:0.490104\tvalid-rmse:0.490741\n",
      "[140]\ttrain-rmse:0.488671\tvalid-rmse:0.490254\n",
      "[150]\ttrain-rmse:0.4875\tvalid-rmse:0.489895\n",
      "[160]\ttrain-rmse:0.486507\tvalid-rmse:0.489691\n",
      "[170]\ttrain-rmse:0.485642\tvalid-rmse:0.489558\n",
      "[180]\ttrain-rmse:0.484919\tvalid-rmse:0.489498\n",
      "[190]\ttrain-rmse:0.484177\tvalid-rmse:0.489482\n",
      "[200]\ttrain-rmse:0.483488\tvalid-rmse:0.489522\n",
      "[210]\ttrain-rmse:0.482874\tvalid-rmse:0.489462\n",
      "[220]\ttrain-rmse:0.482217\tvalid-rmse:0.489398\n",
      "[230]\ttrain-rmse:0.481587\tvalid-rmse:0.489541\n",
      "[240]\ttrain-rmse:0.481072\tvalid-rmse:0.48951\n",
      "[250]\ttrain-rmse:0.480362\tvalid-rmse:0.489618\n",
      "[260]\ttrain-rmse:0.479858\tvalid-rmse:0.489646\n",
      "[270]\ttrain-rmse:0.479399\tvalid-rmse:0.489599\n",
      "[280]\ttrain-rmse:0.478859\tvalid-rmse:0.489676\n",
      "[290]\ttrain-rmse:0.478387\tvalid-rmse:0.489647\n",
      "[300]\ttrain-rmse:0.477884\tvalid-rmse:0.489609\n",
      "[310]\ttrain-rmse:0.47747\tvalid-rmse:0.489584\n",
      "[320]\ttrain-rmse:0.477088\tvalid-rmse:0.489639\n",
      "Stopping. Best iteration:\n",
      "[220]\ttrain-rmse:0.482217\tvalid-rmse:0.489398\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Training ...')\n",
    "\n",
    "params = {}\n",
    "params['objective'] = 'reg:linear'\n",
    "params['eval_metric'] = 'rmse'\n",
    "params['eta'] = 0.04\n",
    "params['max_depth'] = 7\n",
    "params['silent'] = 1\n",
    "\n",
    "watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "clf = xgb.train(params, d_train, 10000, watchlist, early_stopping_rounds=100, verbose_eval=10)\n",
    "\n",
    "del d_train, d_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dow', 'year', 'month', 'ewma', 'holiday_flg', 'days_until_holiday', 'days_since_holiday', 'air_genre_name', 'air_area_name', 'latitude', 'longitude', 'min_visitors', 'mean_visitors', 'median_visitors', 'max_visitors', 'count_observations']\n"
     ]
    }
   ],
   "source": [
    "print(clf.feature_names)\n",
    "#xgb.plot_tree(clf)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Use ewma feature in test set\n",
    "1. Assign ewma to 1st week of test set using last week of training\n",
    "2. Predict\n",
    "3. Calc ewma for 2nd week of test set\n",
    "4. predict again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataframe for last week of training set and only use store\n",
    "x_train_lastWk = train[['air_store_id','visit_date','dow','ewma']]\n",
    "x_train_lastWk = x_train_lastWk[x_train_lastWk['visit_date'] > '2017-04-15']\n",
    "#print(x_train_LastWk.head(2))\n",
    "#x_train_lastWk.head(10)\n",
    "#print(\"total entries: \" + str(len(x_train_LastWk)))\n",
    "#print(\"total stores: \" + str(len(x_train_LastWk['air_store_id'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train_LastWk['dow'] = x_train_LastWk['dow'].astype(str)\n",
    "#x_train_LastWk['store_with_dow']=x_train_LastWk[['air_store_id','dow']].apply(lambda x: '_'.join(x),axis=1)\n",
    "#x_train_LastWk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train_LastWk.groupby('dow')['air_store_id'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split test by weeks [note that weeks start on day 6 (Sunday) rather than day 0 (Monday)]\n",
    "#test['ewma'] = np.random.randint(1, 20, x_test.shape[0])\n",
    "test.index = test['visit_date']\n",
    "#test.head()\n",
    "testWk1 = test['2017-04-23':'2017-04-29']\n",
    "testWk2 = test['2017-04-30':'2017-05-06']\n",
    "testWk3 = test['2017-05-07':'2017-05-13']\n",
    "testWk4 = test['2017-05-14':'2017-05-20']\n",
    "testWk5 = test['2017-05-21':'2017-05-27']\n",
    "testWk6 = test['2017-05-28':'2017-06-01']\n",
    "#testWk6.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "testWk1_pred = pd.merge(testWk1, x_train_lastWk.drop('visit_date',axis=1),how='left',on=['air_store_id','dow'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "testWk1_pred['ewma'] = testWk1_pred['ewma'].fillna(value=0)\n",
    "#testWk1_pred.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Command to put columns in the right order for the XGBoost prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: USE COLUMN LIST BELOW IF NOT INCLUDING VISITOR STATISTICS IN TRAINING SET\n",
    "\n",
    "#columnsForTest_df = ['dow', 'year', 'month', 'ewma', 'holiday_flg', 'days_until_holiday',\n",
    "#       'days_since_holiday', 'air_genre_name', 'air_area_name', 'latitude',\n",
    "#       'longitude']\n",
    "\n",
    "# NOTE: USE COLUMN LIST BELOW IF INCLUDING VISITOR STATISTICS IN TRAINING SET\n",
    "columnsForTest_df = ['dow', 'year', 'month', 'ewma', 'holiday_flg', 'days_until_holiday', 'days_since_holiday',\n",
    "                     'air_genre_name', 'air_area_name', 'latitude', 'longitude', 'min_visitors', 'mean_visitors',\n",
    "                     'median_visitors', 'max_visitors', 'count_observations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_testWk1_pred = testWk1_pred.drop(['id','air_store_id','visit_date','visitors'],axis=1)\n",
    "x_testWk1_pred = x_testWk1_pred[columnsForTest_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_test = xgb.DMatrix(x_testWk1_pred)\n",
    "#del x_test; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting on test ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "308"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Predicting on test ...')\n",
    "p_test = clf.predict(d_test)\n",
    "del d_test; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.90308571,  19.54558182,  24.12433434, ...,   3.55688095,\n",
       "         4.78618813,   7.28006744], dtype=float32)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expm1(p_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "testWk1_pred['visitors'] = np.expm1(p_test)\n",
    "testWk1_pred[['id','visitors']].to_csv('xgb_submission_Wk1.csv', index=False, float_format='%.3f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With test set Week 1 predicted, update ewma and assign to week 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_testWk1_concat = testWk1_pred[train.columns]\n",
    "train_testWk1_concat = pd.concat([train, train_testWk1_concat])\n",
    "train_testWk1_concat = train_testWk1_concat.reset_index()\n",
    "tmp = train_testWk1_concat.groupby(['air_store_id','dow']).apply(lambda x: calc_shifted_ewm(x['visitors'],0.1))\n",
    "tmp = tmp.fillna(method='bfill')\n",
    "tmp.index = tmp.index.get_level_values(2)\n",
    "tmp = tmp.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_testWk1_concat['ewma'] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = train_testWk1_concat[train_testWk1_concat['visit_date'] > testWk2.visit_date.min() - pd.to_timedelta(1, unit='d')]\n",
    "tmp = tmp[['air_store_id','visit_date','dow','ewma']]\n",
    "testWk2_pred = pd.merge(testWk2, tmp.drop('visit_date',axis=1),how='left',on=['air_store_id','dow'])\n",
    "testWk2_pred['ewma'] = testWk2_pred['ewma'].fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['dow', 'year', 'month', 'ewma', 'holiday_flg', 'days_until_holiday',\n",
       "       'days_since_holiday', 'air_genre_name', 'air_area_name', 'latitude',\n",
       "       'longitude', 'min_visitors', 'mean_visitors', 'median_visitors',\n",
       "       'max_visitors', 'count_observations'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_testWk2_pred = testWk2_pred.drop(['id','air_store_id','visit_date','visitors'],axis=1)\n",
    "x_testWk2_pred = x_testWk2_pred[columnsForTest_df]\n",
    "x_testWk2_pred.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_test = xgb.DMatrix(x_testWk2_pred)\n",
    "#del x_test; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictin on test ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "209"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Predictin on test ...')\n",
    "p_test = clf.predict(d_test)\n",
    "del d_test; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "testWk2_pred['visitors'] = np.expm1(p_test)\n",
    "testWk2_pred[['id','visitors']].to_csv('xgb_submission_Wk2.csv',index=False,float_format='%.3f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With test set Week 2 predicted, update ewma and assign to week 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_testWk1_concat.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_testWk2_concat = testWk2_pred[train.columns]\n",
    "train_testWk2_concat = pd.concat([train_testWk1_concat, train_testWk2_concat])\n",
    "train_testWk2_concat = train_testWk2_concat.reset_index()\n",
    "tmp = train_testWk2_concat.groupby(['air_store_id','dow']).apply(lambda x: calc_shifted_ewm(x['visitors'],0.1))\n",
    "tmp = tmp.fillna(method='bfill')\n",
    "tmp.index = tmp.index.get_level_values(2)\n",
    "tmp = tmp.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_testWk2_concat['ewma'] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = train_testWk2_concat[train_testWk2_concat['visit_date'] > testWk3.visit_date.min() - pd.to_timedelta(1, unit='d')]\n",
    "tmp = tmp[['air_store_id','visit_date','dow','ewma']]\n",
    "testWk3_pred = pd.merge(testWk3, tmp.drop('visit_date',axis=1),how='left',on=['air_store_id','dow'])\n",
    "testWk3_pred['ewma'] = testWk3_pred['ewma'].fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_testWk3_pred = testWk3_pred.drop(['id','air_store_id','visit_date','visitors'],axis=1)\n",
    "x_testWk3_pred = x_testWk3_pred[columnsForTest_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_test = xgb.DMatrix(x_testWk3_pred)\n",
    "#del x_test; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictin on test ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Predictin on test ...')\n",
    "p_test = clf.predict(d_test)\n",
    "del d_test; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "testWk3_pred['visitors'] = np.expm1(p_test)\n",
    "testWk3_pred[['id','visitors']].to_csv('xgb_submission_Wk3.csv',index=False,float_format='%.3f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With test set Week 3 predicted, update ewma and assign to week 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_testWk3_concat = pd.concat([train_testWk2_concat[train.columns], testWk3_pred[train.columns]])\n",
    "train_testWk3_concat = train_testWk3_concat.reset_index()\n",
    "tmp = train_testWk3_concat.groupby(['air_store_id','dow']).apply(lambda x: calc_shifted_ewm(x['visitors'],0.1))\n",
    "tmp = tmp.fillna(method='bfill')\n",
    "tmp.index = tmp.index.get_level_values(2)\n",
    "tmp = tmp.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_testWk3_concat['ewma'] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = train_testWk3_concat[train_testWk3_concat['visit_date'] > testWk4.visit_date.min() - pd.to_timedelta(1, unit='d')]\n",
    "tmp = tmp[['air_store_id','visit_date','dow','ewma']]\n",
    "testWk4_pred = pd.merge(testWk4, tmp.drop('visit_date',axis=1),how='left',on=['air_store_id','dow'])\n",
    "testWk4_pred['ewma'] = testWk4_pred['ewma'].fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_testWk4_pred = testWk4_pred.drop(['id','air_store_id','visit_date','visitors'],axis=1)\n",
    "x_testWk4_pred = x_testWk4_pred[columnsForTest_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_test = xgb.DMatrix(x_testWk4_pred)\n",
    "#del x_test; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictin on test ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Predictin on test ...')\n",
    "p_test = clf.predict(d_test)\n",
    "del d_test; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "testWk4_pred['visitors'] = np.expm1(p_test)\n",
    "testWk4_pred[['id','visitors']].to_csv('xgb_submission_Wk4.csv',index=False,float_format='%.3f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With test set Week 4 predicted, update ewma and assign to week 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_testWk4_concat = pd.concat([train_testWk3_concat[train.columns], testWk4_pred[train.columns]])\n",
    "train_testWk4_concat = train_testWk4_concat.reset_index()\n",
    "tmp = train_testWk4_concat.groupby(['air_store_id','dow']).apply(lambda x: calc_shifted_ewm(x['visitors'],0.1))\n",
    "tmp = tmp.fillna(method='bfill')\n",
    "tmp.index = tmp.index.get_level_values(2)\n",
    "tmp = tmp.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_testWk4_concat['ewma'] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = train_testWk4_concat[train_testWk4_concat['visit_date'] > testWk5.visit_date.min() - pd.to_timedelta(1, unit='d')]\n",
    "tmp = tmp[['air_store_id','visit_date','dow','ewma']]\n",
    "testWk5_pred = pd.merge(testWk5, tmp.drop('visit_date',axis=1),how='left',on=['air_store_id','dow'])\n",
    "testWk5_pred['ewma'] = testWk5_pred['ewma'].fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_testWk5_pred = testWk5_pred.drop(['id','air_store_id','visit_date','visitors'],axis=1)\n",
    "x_testWk5_pred = x_testWk5_pred[columnsForTest_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_test = xgb.DMatrix(x_testWk5_pred)\n",
    "#del x_test; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictin on test ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Predictin on test ...')\n",
    "p_test = clf.predict(d_test)\n",
    "del d_test; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "testWk5_pred['visitors'] = np.expm1(p_test)\n",
    "testWk5_pred[['id','visitors']].to_csv('xgb_submission_Wk5.csv',index=False,float_format='%.3f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With test set Week 5 predicted, update ewma and assign to week 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_testWk5_concat = pd.concat([train_testWk4_concat[train.columns], testWk5_pred[train.columns]])\n",
    "train_testWk5_concat = train_testWk5_concat.reset_index()\n",
    "tmp = train_testWk5_concat.groupby(['air_store_id','dow']).apply(lambda x: calc_shifted_ewm(x['visitors'],0.1))\n",
    "tmp = tmp.fillna(method='bfill')\n",
    "tmp.index = tmp.index.get_level_values(2)\n",
    "tmp = tmp.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_testWk5_concat['ewma'] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = train_testWk5_concat[train_testWk5_concat['visit_date'] > testWk6.visit_date.min() - pd.to_timedelta(1, unit='d')]\n",
    "tmp = tmp[['air_store_id','visit_date','dow','ewma']]\n",
    "testWk6_pred = pd.merge(testWk6, tmp.drop('visit_date',axis=1),how='left',on=['air_store_id','dow'])\n",
    "testWk6_pred['ewma'] = testWk6_pred['ewma'].fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_testWk6_pred = testWk6_pred.drop(['id','air_store_id','visit_date','visitors'],axis=1)\n",
    "x_testWk6_pred = x_testWk6_pred[columnsForTest_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_test = xgb.DMatrix(x_testWk6_pred)\n",
    "#del x_test; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictin on test ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Predictin on test ...')\n",
    "p_test = clf.predict(d_test)\n",
    "del d_test; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "testWk6_pred['visitors'] = np.expm1(p_test)\n",
    "testWk6_pred[['id','visitors']].to_csv('xgb_submission_Wk6.csv',index=False,float_format='%.3f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile all prediction csv and sort in order needed for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_wk1 = pd.read_csv('xgb_submission_Wk1.csv')\n",
    "pred_wk2 = pd.read_csv('xgb_submission_Wk2.csv')\n",
    "pred_wk3 = pd.read_csv('xgb_submission_Wk3.csv')\n",
    "pred_wk4 = pd.read_csv('xgb_submission_Wk4.csv')\n",
    "pred_wk5 = pd.read_csv('xgb_submission_Wk5.csv')\n",
    "pred_wk6 = pd.read_csv('xgb_submission_Wk6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_predictions = pd.concat([pred_wk1,pred_wk2,pred_wk3,pred_wk4,pred_wk5,pred_wk6]).sort_values(by='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_predictions[['id','visitors']].to_csv('xgb_submission.csv',index=False,float_format='%.3f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(compiled_predictions['id'].tail(20))\n",
    "#print(data['sampleSub']['id'].tail(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note about cells below:\n",
    "\n",
    "Cell below were an attempt to modify visitors manually on restaurants that did not have data for particular day-of-week on the training set, under the assumption that if the day-of-week was not included it was due to the restaurant being closed. Thus, visitors would intuitively be 0 for that date. However, it worsened the RMSE score by about 5-6%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "(32019, 2)\n",
      "(32019, 7)\n"
     ]
    }
   ],
   "source": [
    "chk = np.where(compiled_predictions['id'] != data['sampleSub']['id'])\n",
    "print(compiled_predictions[['id']].equals(data['sampleSub'][['id']]))\n",
    "print(compiled_predictions.shape)\n",
    "print(data['sampleSub'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "air_store_id\n",
       "air_00a91d42b08b08d9    [4, 5, 0, 1, 2, 3, 6]\n",
       "air_0164b9927d20bcc3       [0, 1, 2, 3, 4, 5]\n",
       "air_0241aa3964b7f861    [6, 0, 1, 2, 4, 5, 3]\n",
       "air_0328696196e46f18    [6, 0, 1, 2, 3, 4, 5]\n",
       "air_034a3d5b40d5b1b1    [4, 5, 6, 0, 2, 3, 1]\n",
       "Name: dow, dtype: object"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chk_days_open = data['airVisit'].groupby('air_store_id')['dow'].unique()\n",
    "chk_days_open.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>air_store_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>air_00a91d42b08b08d9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>air_0164b9927d20bcc3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>air_0241aa3964b7f861</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>air_0328696196e46f18</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>air_034a3d5b40d5b1b1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0  1  2  3  4  5  6\n",
       "air_store_id                             \n",
       "air_00a91d42b08b08d9  1  1  1  1  1  1  1\n",
       "air_0164b9927d20bcc3  1  1  1  1  1  1  0\n",
       "air_0241aa3964b7f861  1  1  1  1  1  1  1\n",
       "air_0328696196e46f18  1  1  1  1  1  1  1\n",
       "air_034a3d5b40d5b1b1  1  1  1  1  1  1  1"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chk_days_closed = pd.DataFrame(chk_days_open.values.tolist(), index=chk_days_open.index)\n",
    "chk_days_closed = ~chk_days_closed.isnull()*1\n",
    "chk_days_closed.head() \n",
    "#chk_days_closed['air_store_id']=chk_days_closed.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "air_store_id           \n",
       "air_00a91d42b08b08d9  0    1\n",
       "                      1    1\n",
       "                      2    1\n",
       "                      3    1\n",
       "                      4    1\n",
       "                      5    1\n",
       "                      6    1\n",
       "air_0164b9927d20bcc3  0    1\n",
       "                      1    1\n",
       "                      2    1\n",
       "                      3    1\n",
       "                      4    1\n",
       "                      5    1\n",
       "                      6    0\n",
       "air_0241aa3964b7f861  0    1\n",
       "                      1    1\n",
       "                      2    1\n",
       "                      3    1\n",
       "                      4    1\n",
       "                      5    1\n",
       "dtype: int32"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chk_days_closed = chk_days_closed.stack()\n",
    "chk_days_closed.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chk_days_closed['air_store_id'] = chk_days_closed.index\n",
    "chk_days_closed = chk_days_closed.reset_index().rename(columns={'level_1': 'dow', 0: 'open_closed'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>dow</th>\n",
       "      <th>open_closed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>air_0164b9927d20bcc3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>air_0164b9927d20bcc3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>air_0164b9927d20bcc3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>air_0164b9927d20bcc3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>air_0164b9927d20bcc3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>air_0164b9927d20bcc3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>air_0164b9927d20bcc3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>air_0241aa3964b7f861</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>air_0241aa3964b7f861</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>air_0241aa3964b7f861</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>air_0241aa3964b7f861</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>air_0241aa3964b7f861</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>air_0241aa3964b7f861</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            air_store_id  dow  open_closed\n",
       "0   air_00a91d42b08b08d9    0            1\n",
       "1   air_00a91d42b08b08d9    1            1\n",
       "2   air_00a91d42b08b08d9    2            1\n",
       "3   air_00a91d42b08b08d9    3            1\n",
       "4   air_00a91d42b08b08d9    4            1\n",
       "5   air_00a91d42b08b08d9    5            1\n",
       "6   air_00a91d42b08b08d9    6            1\n",
       "7   air_0164b9927d20bcc3    0            1\n",
       "8   air_0164b9927d20bcc3    1            1\n",
       "9   air_0164b9927d20bcc3    2            1\n",
       "10  air_0164b9927d20bcc3    3            1\n",
       "11  air_0164b9927d20bcc3    4            1\n",
       "12  air_0164b9927d20bcc3    5            1\n",
       "13  air_0164b9927d20bcc3    6            0\n",
       "14  air_0241aa3964b7f861    0            1\n",
       "15  air_0241aa3964b7f861    1            1\n",
       "16  air_0241aa3964b7f861    2            1\n",
       "17  air_0241aa3964b7f861    3            1\n",
       "18  air_0241aa3964b7f861    4            1\n",
       "19  air_0241aa3964b7f861    5            1"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chk_days_closed.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_sub = pd.DataFrame.from_csv('xgb_submission.csv')\n",
    "compiled_sub = compiled_sub.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>visitors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-23</td>\n",
       "      <td>2.368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-24</td>\n",
       "      <td>23.760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-25</td>\n",
       "      <td>26.364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-26</td>\n",
       "      <td>28.635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-27</td>\n",
       "      <td>28.899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id  visitors\n",
       "0  air_00a91d42b08b08d9_2017-04-23     2.368\n",
       "1  air_00a91d42b08b08d9_2017-04-24    23.760\n",
       "2  air_00a91d42b08b08d9_2017-04-25    26.364\n",
       "3  air_00a91d42b08b08d9_2017-04-26    28.635\n",
       "4  air_00a91d42b08b08d9_2017-04-27    28.899"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiled_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>visitors</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>dow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-23</td>\n",
       "      <td>2.368</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-24</td>\n",
       "      <td>23.760</td>\n",
       "      <td>2017-04-24</td>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-25</td>\n",
       "      <td>26.364</td>\n",
       "      <td>2017-04-25</td>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-26</td>\n",
       "      <td>28.635</td>\n",
       "      <td>2017-04-26</td>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-27</td>\n",
       "      <td>28.899</td>\n",
       "      <td>2017-04-27</td>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id  visitors visit_date          air_store_id  \\\n",
       "0  air_00a91d42b08b08d9_2017-04-23     2.368 2017-04-23  air_00a91d42b08b08d9   \n",
       "1  air_00a91d42b08b08d9_2017-04-24    23.760 2017-04-24  air_00a91d42b08b08d9   \n",
       "2  air_00a91d42b08b08d9_2017-04-25    26.364 2017-04-25  air_00a91d42b08b08d9   \n",
       "3  air_00a91d42b08b08d9_2017-04-26    28.635 2017-04-26  air_00a91d42b08b08d9   \n",
       "4  air_00a91d42b08b08d9_2017-04-27    28.899 2017-04-27  air_00a91d42b08b08d9   \n",
       "\n",
       "   dow  \n",
       "0    6  \n",
       "1    0  \n",
       "2    1  \n",
       "3    2  \n",
       "4    3  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiled_sub['visit_date'] = compiled_sub['id'].map(lambda x: str(x).split('_')[2])\n",
    "compiled_sub['air_store_id'] = compiled_sub['id'].map(lambda x: '_'.join(str(x).split('_')[:2]))\n",
    "compiled_sub['visit_date'] = pd.to_datetime(compiled_sub['visit_date'])\n",
    "compiled_sub['dow'] = compiled_sub['visit_date'].dt.dayofweek\n",
    "compiled_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_sub = pd.merge(compiled_sub, chk_days_closed, how='left', on=['air_store_id','dow'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#updated_sub.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_visitors = updated_sub['visitors'] * updated_sub['open_closed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     2.368\n",
       "1    23.760\n",
       "2    26.364\n",
       "3    28.635\n",
       "4    28.899\n",
       "5    34.935\n",
       "6    13.303\n",
       "7     4.340\n",
       "8     3.381\n",
       "9     5.168\n",
       "dtype: float64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrected_visitors.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_pred = compiled_sub\n",
    "updated_pred['visitors'] = corrected_visitors\n",
    "#updated_pred.head(39)\n",
    "updated_pred[['id','visitors']].to_csv('xgb_updated_submission.csv',index=False,float_format='%.3f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
