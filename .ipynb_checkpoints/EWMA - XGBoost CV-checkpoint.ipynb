{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "mingw_path = 'C:\\\\Program Files\\\\mingw-w64\\\\x86_64-7.2.0-posix-seh-rt_v5-rev1\\\\mingw64\\\\bin'\n",
    "os.environ['PATH'] = mingw_path + ';' + os.environ['PATH']\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import gc # Note: this is a garbage collector\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bring in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = r\"..\\Raw_Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'airStore':  pd.read_csv(PATH + r\"\\air_store_info.csv\"),\n",
    "    'airVisit':  pd.read_csv(PATH + r\"\\air_visit_data.csv\"),\n",
    "    'date':      pd.read_csv(PATH + r\"\\date_info.csv\"),\n",
    "    'sampleSub': pd.read_csv(PATH + r\"\\sample_submission.csv\"),\n",
    "    'storeIDs':  pd.read_csv(PATH + r\"\\store_id_relation.csv\")    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['date']['visit_date'] = pd.to_datetime(data['date']['calendar_date'])\n",
    "data['date'].drop('calendar_date', axis = 1 , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['airVisit']['visit_date'] = pd.to_datetime(data['airVisit']['visit_date'])\n",
    "data['airVisit']['dow'] = data['airVisit']['visit_date'].dt.dayofweek\n",
    "data['airVisit']['year'] = data['airVisit']['visit_date'].dt.year\n",
    "data['airVisit']['month'] = data['airVisit']['visit_date'].dt.month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add EWMA of visits as feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to calculate ewm (note, found this on the competition discussion forum):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_shifted_ewm(series, alpha, adjust = True):\n",
    "    return series.shift().ewm(alpha = alpha, adjust = adjust).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step below adds the ewm by day of week. Right now I'm returning a separate series so I can look at what each step does if I want to\n",
    "tmp = data['airVisit'].groupby(['air_store_id','dow']).apply(lambda x: calc_shifted_ewm(x['visitors'], 0.1)) \n",
    "# This step backfills the 1st week's dow for each restaurant, otherwise it would be NaN since it's a 1-period ewma\n",
    "tmp = tmp.fillna(method='bfill')\n",
    "# The groupby function returns a multiIndex Series. I only need the 3rd level (original df index) to add column to original df\n",
    "tmp.index = tmp.index.get_level_values(2)\n",
    "# Sort index before adding back to original df\n",
    "tmp = tmp.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['airVisit']['ewma'] = tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add 'days since last' and 'days until next' holiday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 'days since holiday' feature\n",
    "daysSinceList = []\n",
    "daysSinceHol = 0 # initialize daysSince counter\n",
    "for row in data['date']['holiday_flg']:\n",
    "    if row == 1:\n",
    "        daysSinceHol = 0\n",
    "        daysSinceList.append(daysSinceHol)\n",
    "    else:\n",
    "        daysSinceHol += 1\n",
    "        daysSinceList.append(daysSinceHol)\n",
    "data['date']['days_since_holiday'] = daysSinceList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 'days UNTIL next holiday' feature\n",
    "holidayList = list(data['date']['holiday_flg'])\n",
    "daysUntilHolList = np.zeros(len(holidayList),dtype=np.int)\n",
    "daysUntilHol = 0 # initialize daysUntilHol counter\n",
    "for i in range(len(holidayList)-1,0,-1):\n",
    "    if holidayList[i] == 1:\n",
    "        daysUntilHol = 0\n",
    "        daysUntilHolList[i] = daysUntilHol\n",
    "    else:\n",
    "        daysUntilHol += 1\n",
    "        daysUntilHolList[i] = daysUntilHol        \n",
    "data['date']['days_until_holiday'] = daysUntilHolList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge air_visits with date dframe to get holiday info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "colsToMerge = ['holiday_flg','visit_date','days_until_holiday','days_since_holiday']\n",
    "df_train = pd.merge(data['airVisit'], data['date'][colsToMerge], how = 'left', on = 'visit_date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter only the stores that must be predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = data['sampleSub']\n",
    "\n",
    "df_test['visit_date'] = df_test['id'].map(lambda x: str(x).split('_')[2])\n",
    "df_test['air_store_id'] = df_test['id'].map(lambda x: '_'.join(str(x).split('_')[:2]))\n",
    "df_test['visit_date'] = pd.to_datetime(df_test['visit_date'])\n",
    "df_test['dow'] = df_test['visit_date'].dt.dayofweek\n",
    "df_test['year'] = df_test['visit_date'].dt.year\n",
    "df_test['month'] = df_test['visit_date'].dt.month\n",
    "\n",
    "unique_stores = df_test['air_store_id'].unique()\n",
    "stores = pd.concat([pd.DataFrame({'air_store_id': unique_stores, 'dow': [i]*len(unique_stores)}) for i in range(7)], axis=0, ignore_index=True).reset_index(drop=True)\n",
    "#stores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge df_test with date dframe to get holiday info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.merge(df_test, data['date'][colsToMerge], how = 'left', on = 'visit_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores = pd.merge(stores, data['airStore'], how='left', on=['air_store_id'])\n",
    "#stores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical string variables \n",
    "lbl = LabelEncoder()\n",
    "stores['air_genre_name'] = lbl.fit_transform(stores['air_genre_name'])\n",
    "stores['air_area_name'] = lbl.fit_transform(stores['air_area_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add genre and area to train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.merge(df_train, stores, how = 'left', on = ['air_store_id','dow'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add visitor statistics as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df_train.groupby(['air_store_id','dow']).agg({'visitors' : [np.min,np.mean,np.median,np.max,np.size]}).reset_index()\n",
    "tmp.columns = ['air_store_id', 'dow', 'min_visitors', 'mean_visitors', 'median_visitors','max_visitors','count_observations']\n",
    "df_train = pd.merge(df_train, tmp, how='left', on=['air_store_id','dow'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.merge(df_test, stores, how = 'left', on = ['air_store_id','dow'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.merge(df_test, tmp, how='left', on=['air_store_id','dow'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: For XGB, didn't fillna (1/28/2018)\n",
    "Other algorithms need fillna. TODO: 1) investigate why there are NaN on train set. 2) Check if XGBoost gets better score with fillna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.fillna(-1)\n",
    "df_test = df_test.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_train\n",
    "test = df_test\n",
    "col = [c for c in train if c not in ['id', 'air_store_id','visit_date','visitors']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize XGBoost\n",
    "Note - code based on:\n",
    "https://www.kaggle.com/jmbull/no-xgb-starter-here-s-one-lb-507"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binding to float32\n"
     ]
    }
   ],
   "source": [
    "# XGB starter template borrowed from @anokas\n",
    "# https://www.kaggle.com/anokas/simple-xgboost-starter-0-0655\n",
    "\n",
    "print('Binding to float32')\n",
    "\n",
    "for c, dtype in zip(df_train.columns, train.dtypes):\n",
    "    if dtype == np.float64:\n",
    "        train[c] = train[c].astype(np.float32)\n",
    "        \n",
    "for c, dtype in zip(df_test.columns, test.dtypes):\n",
    "    if dtype == np.float64:\n",
    "        test[c] = test[c].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train.drop(['air_store_id','visit_date','visitors'], axis=1)\n",
    "y_train = np.log1p(train['visitors'].values)\n",
    "\n",
    "# Get Column order for x_test df\n",
    "colOrder = x_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building DMatrix...\n"
     ]
    }
   ],
   "source": [
    "# Create training / validation split\n",
    "split = 200000\n",
    "x_train, y_train, x_valid, y_valid = x_train[:split], y_train[:split], x_train[split:], y_train[split:]\n",
    "\n",
    "print('Building DMatrix...')\n",
    "\n",
    "d_train = xgb.DMatrix(x_train, label=y_train)\n",
    "d_valid = xgb.DMatrix(x_valid, label=y_valid)\n",
    "\n",
    "#del x_train, x_valid; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ...\n",
      "[0]\ttrain-rmse:2.35531\tvalid-rmse:2.31585\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 100 rounds.\n",
      "[25]\ttrain-rmse:0.973041\tvalid-rmse:0.959437\n",
      "[50]\ttrain-rmse:0.585434\tvalid-rmse:0.578736\n",
      "[75]\ttrain-rmse:0.50985\tvalid-rmse:0.505621\n",
      "[100]\ttrain-rmse:0.495646\tvalid-rmse:0.493645\n",
      "[125]\ttrain-rmse:0.490914\tvalid-rmse:0.49115\n",
      "[150]\ttrain-rmse:0.487584\tvalid-rmse:0.490177\n",
      "[175]\ttrain-rmse:0.485131\tvalid-rmse:0.489855\n",
      "[200]\ttrain-rmse:0.483508\tvalid-rmse:0.489624\n",
      "[225]\ttrain-rmse:0.481949\tvalid-rmse:0.489472\n",
      "[250]\ttrain-rmse:0.480349\tvalid-rmse:0.489633\n",
      "[275]\ttrain-rmse:0.478961\tvalid-rmse:0.489721\n",
      "[300]\ttrain-rmse:0.477639\tvalid-rmse:0.489728\n",
      "[325]\ttrain-rmse:0.476233\tvalid-rmse:0.48994\n",
      "Stopping. Best iteration:\n",
      "[225]\ttrain-rmse:0.481949\tvalid-rmse:0.489472\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Training ...')\n",
    "\n",
    "params = {}\n",
    "params['objective'] = 'reg:linear'\n",
    "params['eval_metric'] = 'rmse'\n",
    "params['eta'] = 0.04\n",
    "params['max_depth'] = 7\n",
    "params['silent'] = 1\n",
    "\n",
    "watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "clf = xgb.train(params, d_train, 10000, watchlist, early_stopping_rounds=100, verbose_eval=25)\n",
    "\n",
    "#del d_train, d_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(clf.feature_names)\n",
    "#xgb.plot_tree(clf, num_trees=0,rankdir='LR')\n",
    "#fig = plt.gcf()\n",
    "#fig.set_size_inches(150, 100)\n",
    "#fig.savefig('tree.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgb.plot_importance(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use ewma feature in test set\n",
    "1. Assign ewma to 1st week of test set using last week of training\n",
    "2. Predict\n",
    "3. Calc ewma for 2nd week of test set\n",
    "4. predict again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataframe for last week of training set and only use store\n",
    "x_train_lastWk = train[['air_store_id','visit_date','dow','ewma']]\n",
    "x_train_lastWk = x_train_lastWk[x_train_lastWk['visit_date'] > '2017-04-15']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split test by weeks [note that weeks start on day 6 (Sunday) rather than day 0 (Monday)]\n",
    "test.index = test['visit_date']\n",
    "\n",
    "testWk1 = test['2017-04-23':'2017-04-29']\n",
    "testWk2 = test['2017-04-30':'2017-05-06']\n",
    "testWk3 = test['2017-05-07':'2017-05-13']\n",
    "testWk4 = test['2017-05-14':'2017-05-20']\n",
    "testWk5 = test['2017-05-21':'2017-05-27']\n",
    "testWk6 = test['2017-05-28':'2017-06-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "testWk1_pred = pd.merge(testWk1, x_train_lastWk.drop('visit_date',axis=1),how='left',on=['air_store_id','dow'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testWk1_pred['ewma'] = testWk1_pred['ewma'].fillna(value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Command to put columns in the right order for the XGBoost prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: USE COLUMN LIST BELOW IF NOT INCLUDING VISITOR STATISTICS IN TRAINING SET\n",
    "\n",
    "#columnsForTest_df = ['dow', 'year', 'month', 'ewma', 'holiday_flg', 'days_until_holiday',\n",
    "#       'days_since_holiday', 'air_genre_name', 'air_area_name', 'latitude',\n",
    "#       'longitude']\n",
    "\n",
    "# NOTE: USE COLUMN LIST BELOW IF INCLUDING VISITOR STATISTICS IN TRAINING SET\n",
    "columnsForTest_df = ['dow', 'year', 'month', 'ewma', 'holiday_flg', 'days_until_holiday', 'days_since_holiday',\n",
    "                     'air_genre_name', 'air_area_name', 'latitude', 'longitude', 'min_visitors', 'mean_visitors',\n",
    "                     'median_visitors', 'max_visitors', 'count_observations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_testWk1_pred = testWk1_pred.drop(['id','air_store_id','visit_date','visitors'],axis=1)\n",
    "x_testWk1_pred = x_testWk1_pred[columnsForTest_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_test = xgb.DMatrix(x_testWk1_pred)\n",
    "#del x_test; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting on test ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "159"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Predicting on test ...')\n",
    "p_test = clf.predict(d_test)\n",
    "del d_test; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "testWk1_pred['visitors'] = np.expm1(p_test)\n",
    "testWk1_pred[['id','visitors']].to_csv('xgb_submission_Wk1.csv', index=False, float_format='%.3f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With test set Week 1 predicted, update ewma and assign to week 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_testWk1_concat = testWk1_pred[train.columns]\n",
    "train_testWk1_concat = pd.concat([train, train_testWk1_concat])\n",
    "train_testWk1_concat = train_testWk1_concat.reset_index()\n",
    "tmp = train_testWk1_concat.groupby(['air_store_id','dow']).apply(lambda x: calc_shifted_ewm(x['visitors'],0.1))\n",
    "tmp = tmp.fillna(method='bfill')\n",
    "tmp.index = tmp.index.get_level_values(2)\n",
    "tmp = tmp.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_testWk1_concat['ewma'] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = train_testWk1_concat[train_testWk1_concat['visit_date'] > testWk2.visit_date.min() - pd.to_timedelta(1, unit='d')]\n",
    "tmp = tmp[['air_store_id','visit_date','dow','ewma']]\n",
    "testWk2_pred = pd.merge(testWk2, tmp.drop('visit_date',axis=1),how='left',on=['air_store_id','dow'])\n",
    "testWk2_pred['ewma'] = testWk2_pred['ewma'].fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_testWk2_pred = testWk2_pred.drop(['id','air_store_id','visit_date','visitors'],axis=1)\n",
    "x_testWk2_pred = x_testWk2_pred[columnsForTest_df]\n",
    "#x_testWk2_pred.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_test = xgb.DMatrix(x_testWk2_pred)\n",
    "#del x_test; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictin on test ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Predictin on test ...')\n",
    "p_test = clf.predict(d_test)\n",
    "del d_test; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "testWk2_pred['visitors'] = np.expm1(p_test)\n",
    "testWk2_pred[['id','visitors']].to_csv('xgb_submission_Wk2.csv',index=False,float_format='%.3f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With test set Week 2 predicted, update ewma and assign to week 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_testWk2_concat = testWk2_pred[train.columns]\n",
    "train_testWk2_concat = pd.concat([train_testWk1_concat, train_testWk2_concat])\n",
    "train_testWk2_concat = train_testWk2_concat.reset_index()\n",
    "tmp = train_testWk2_concat.groupby(['air_store_id','dow']).apply(lambda x: calc_shifted_ewm(x['visitors'],0.1))\n",
    "tmp = tmp.fillna(method='bfill')\n",
    "tmp.index = tmp.index.get_level_values(2)\n",
    "tmp = tmp.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_testWk2_concat['ewma'] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = train_testWk2_concat[train_testWk2_concat['visit_date'] > testWk3.visit_date.min() - pd.to_timedelta(1, unit='d')]\n",
    "tmp = tmp[['air_store_id','visit_date','dow','ewma']]\n",
    "testWk3_pred = pd.merge(testWk3, tmp.drop('visit_date',axis=1),how='left',on=['air_store_id','dow'])\n",
    "testWk3_pred['ewma'] = testWk3_pred['ewma'].fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_testWk3_pred = testWk3_pred.drop(['id','air_store_id','visit_date','visitors'],axis=1)\n",
    "x_testWk3_pred = x_testWk3_pred[columnsForTest_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_test = xgb.DMatrix(x_testWk3_pred)\n",
    "#del x_test; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictin on test ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Predictin on test ...')\n",
    "p_test = clf.predict(d_test)\n",
    "del d_test; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "testWk3_pred['visitors'] = np.expm1(p_test)\n",
    "testWk3_pred[['id','visitors']].to_csv('xgb_submission_Wk3.csv',index=False,float_format='%.3f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With test set Week 3 predicted, update ewma and assign to week 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_testWk3_concat = pd.concat([train_testWk2_concat[train.columns], testWk3_pred[train.columns]])\n",
    "train_testWk3_concat = train_testWk3_concat.reset_index()\n",
    "tmp = train_testWk3_concat.groupby(['air_store_id','dow']).apply(lambda x: calc_shifted_ewm(x['visitors'],0.1))\n",
    "tmp = tmp.fillna(method='bfill')\n",
    "tmp.index = tmp.index.get_level_values(2)\n",
    "tmp = tmp.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_testWk3_concat['ewma'] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = train_testWk3_concat[train_testWk3_concat['visit_date'] > testWk4.visit_date.min() - pd.to_timedelta(1, unit='d')]\n",
    "tmp = tmp[['air_store_id','visit_date','dow','ewma']]\n",
    "testWk4_pred = pd.merge(testWk4, tmp.drop('visit_date',axis=1),how='left',on=['air_store_id','dow'])\n",
    "testWk4_pred['ewma'] = testWk4_pred['ewma'].fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_testWk4_pred = testWk4_pred.drop(['id','air_store_id','visit_date','visitors'],axis=1)\n",
    "x_testWk4_pred = x_testWk4_pred[columnsForTest_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_test = xgb.DMatrix(x_testWk4_pred)\n",
    "#del x_test; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictin on test ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Predictin on test ...')\n",
    "p_test = clf.predict(d_test)\n",
    "del d_test; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "testWk4_pred['visitors'] = np.expm1(p_test)\n",
    "testWk4_pred[['id','visitors']].to_csv('xgb_submission_Wk4.csv',index=False,float_format='%.3f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With test set Week 4 predicted, update ewma and assign to week 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_testWk4_concat = pd.concat([train_testWk3_concat[train.columns], testWk4_pred[train.columns]])\n",
    "train_testWk4_concat = train_testWk4_concat.reset_index()\n",
    "tmp = train_testWk4_concat.groupby(['air_store_id','dow']).apply(lambda x: calc_shifted_ewm(x['visitors'],0.1))\n",
    "tmp = tmp.fillna(method='bfill')\n",
    "tmp.index = tmp.index.get_level_values(2)\n",
    "tmp = tmp.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_testWk4_concat['ewma'] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = train_testWk4_concat[train_testWk4_concat['visit_date'] > testWk5.visit_date.min() - pd.to_timedelta(1, unit='d')]\n",
    "tmp = tmp[['air_store_id','visit_date','dow','ewma']]\n",
    "testWk5_pred = pd.merge(testWk5, tmp.drop('visit_date',axis=1),how='left',on=['air_store_id','dow'])\n",
    "testWk5_pred['ewma'] = testWk5_pred['ewma'].fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_testWk5_pred = testWk5_pred.drop(['id','air_store_id','visit_date','visitors'],axis=1)\n",
    "x_testWk5_pred = x_testWk5_pred[columnsForTest_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_test = xgb.DMatrix(x_testWk5_pred)\n",
    "#del x_test; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictin on test ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Predictin on test ...')\n",
    "p_test = clf.predict(d_test)\n",
    "del d_test; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "testWk5_pred['visitors'] = np.expm1(p_test)\n",
    "testWk5_pred[['id','visitors']].to_csv('xgb_submission_Wk5.csv',index=False,float_format='%.3f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With test set Week 5 predicted, update ewma and assign to week 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_testWk5_concat = pd.concat([train_testWk4_concat[train.columns], testWk5_pred[train.columns]])\n",
    "train_testWk5_concat = train_testWk5_concat.reset_index()\n",
    "tmp = train_testWk5_concat.groupby(['air_store_id','dow']).apply(lambda x: calc_shifted_ewm(x['visitors'],0.1))\n",
    "tmp = tmp.fillna(method='bfill')\n",
    "tmp.index = tmp.index.get_level_values(2)\n",
    "tmp = tmp.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_testWk5_concat['ewma'] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = train_testWk5_concat[train_testWk5_concat['visit_date'] > testWk6.visit_date.min() - pd.to_timedelta(1, unit='d')]\n",
    "tmp = tmp[['air_store_id','visit_date','dow','ewma']]\n",
    "testWk6_pred = pd.merge(testWk6, tmp.drop('visit_date',axis=1),how='left',on=['air_store_id','dow'])\n",
    "testWk6_pred['ewma'] = testWk6_pred['ewma'].fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_testWk6_pred = testWk6_pred.drop(['id','air_store_id','visit_date','visitors'],axis=1)\n",
    "x_testWk6_pred = x_testWk6_pred[columnsForTest_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_test = xgb.DMatrix(x_testWk6_pred)\n",
    "#del x_test; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictin on test ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Predictin on test ...')\n",
    "p_test = clf.predict(d_test)\n",
    "del d_test; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "testWk6_pred['visitors'] = np.expm1(p_test)\n",
    "testWk6_pred[['id','visitors']].to_csv('xgb_submission_Wk6.csv',index=False,float_format='%.3f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile all prediction csv and sort in order needed for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_wk1 = pd.read_csv('xgb_submission_Wk1.csv')\n",
    "pred_wk2 = pd.read_csv('xgb_submission_Wk2.csv')\n",
    "pred_wk3 = pd.read_csv('xgb_submission_Wk3.csv')\n",
    "pred_wk4 = pd.read_csv('xgb_submission_Wk4.csv')\n",
    "pred_wk5 = pd.read_csv('xgb_submission_Wk5.csv')\n",
    "pred_wk6 = pd.read_csv('xgb_submission_Wk6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_predictions = pd.concat([pred_wk1,pred_wk2,pred_wk3,pred_wk4,pred_wk5,pred_wk6]).sort_values(by='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_predictions[['id','visitors']].to_csv('xgb_submission.csv',index=False,float_format='%.3f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check tree characteristics for hyperparameter turning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelfit(alg, dtrain, predictors,useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "    \n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(dtrain[predictors].values, label=dtrain.get_labels())\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics='rmse', early_stopping_rounds=early_stopping_rounds, show_progress=False)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(dtrain[predictors], dtrain['Disbursed'],eval_metric='auc')\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "    dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n",
    "        \n",
    "    #Print model report:\n",
    "    print \"\\nModel Report\"\n",
    "    print \"Accuracy : %.4g\" % metrics.accuracy_score(dtrain['Disbursed'].values, dtrain_predictions)\n",
    "    print \"AUC Score (Train): %f\" % metrics.roc_auc_score(dtrain['Disbursed'], dtrain_predprob)\n",
    "                    \n",
    "    feat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)\n",
    "    feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "    plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Booster' object has no attribute 'get_xgb_params'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-130-86eab26260dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_xgb_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Booster' object has no attribute 'get_xgb_params'"
     ]
    }
   ],
   "source": [
    "clf.get_xgb_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.25809654,  3.49650756,  3.40119738, ...,  3.29583687,\n",
       "        3.09104245,  3.61091791])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
